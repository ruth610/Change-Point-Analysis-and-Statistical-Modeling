{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedd3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "# Visual settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    df = pd.read_csv('../data/BrentOilPrices_Processed.csv', index_col='Date', parse_dates=True)\n",
    "    # If the processed file doesn't exist, try original\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        df = pd.read_csv('../data/BrentOilPrices.csv')\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%d-%b-%y')\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df.sort_index(inplace=True)\n",
    "    except FileNotFoundError:\n",
    "         # Dummy generation again for safety\n",
    "        print(\"Data not found. Generating dummy data.\")\n",
    "        dates = pd.date_range(start='1987-05-20', end='2022-09-30', freq='D')\n",
    "        df = pd.DataFrame({\n",
    "            'Price': np.concatenate([\n",
    "                np.random.normal(20, 2, 5000),\n",
    "                np.random.normal(50, 5, 4000),\n",
    "                np.random.normal(100, 10, len(dates)-9000)\n",
    "            ])\n",
    "        }, index=dates)\n",
    "\n",
    "# Filter for a specific range if needed to speed up calculation for demo (e.g., last 10 years)\n",
    "# For full analysis, we use the whole dataset or specific periods of interest.\n",
    "# df = df['2010':]\n",
    "\n",
    "print(df.head())\n",
    "plt.plot(df.index, df['Price'])\n",
    "plt.title('Brent Oil Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511fca61",
   "metadata": {},
   "source": [
    "## 2. Load Event Data\n",
    "Load the list of key geopolitical events to overlay on our results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1aa509",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    events_df = pd.read_csv('../data/events_template.csv')\n",
    "    events_df['Date'] = pd.to_datetime(events_df['Date'])\n",
    "    print(\"Events loaded:\")\n",
    "    print(events_df[['Date', 'Event']])\n",
    "except FileNotFoundError:\n",
    "    print(\"Events file not found.\")\n",
    "    events_df = pd.DataFrame(columns=['Date', 'Event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef66d39c",
   "metadata": {},
   "source": [
    "## 3. Bayesian Change Point Model with PyMC\n",
    "We will model the price data assuming there is a single \"switch point\" ($\\tau$) where the mean price changes from $\\mu_1$ to $\\mu_2$.\n",
    "\n",
    "**Model Specification:**\n",
    "1.  **Prior for $\\tau$**: Discrete Uniform distribution over the time indices.\n",
    "2.  **Priors for $\\mu_1, \\mu_2$**: Normal distributions (or Exponential if modeling positive values strictly).\n",
    "3.  **Prior for $\\sigma$**: Exponential distribution (for noise).\n",
    "4.  **Likelihood**: Normal distribution $y \\sim \\mathcal{N}(\\mu, \\sigma)$ where $\\mu$ switches at $\\tau$.\n",
    "\n",
    "*Note: For count data, Poisson is often used, but Price is continuous.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a349e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PyMC\n",
    "y_data = df['Price'].values\n",
    "n_count = len(y_data)\n",
    "idx = np.arange(n_count)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # 1. Define the Switch Point (tau)\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n_count - 1)\n",
    "\n",
    "    # 2. Define Priors for Means\n",
    "    # We can use the overall mean as a starting point\n",
    "    mean_price = y_data.mean()\n",
    "    mu_1 = pm.Normal(\"mu_1\", mu=mean_price, sigma=20)\n",
    "    mu_2 = pm.Normal(\"mu_2\", mu=mean_price, sigma=20)\n",
    "\n",
    "    # 3. Define Prior for Sigma\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1.0)\n",
    "\n",
    "    # 4. Define the Switch Function\n",
    "    # pm.math.switch(condition, then, else)\n",
    "    mu = pm.math.switch(tau >= idx, mu_1, mu_2)\n",
    "\n",
    "    # 5. Define Likelihood\n",
    "    observation = pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=y_data)\n",
    "\n",
    "    # 6. Run the Sampler\n",
    "    # Starting with a smaller number of samples for demonstration/speed\n",
    "    trace = pm.sample(1000, tune=1000, return_inferencedata=True)\n",
    "\n",
    "print(\"Sampling complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257e501",
   "metadata": {},
   "source": [
    "## 4. Model Diagnostics\n",
    "Check for convergence using `r_hat` and trace plots.\n",
    "- `r_hat` should be close to 1.0 (< 1.05).\n",
    "- Trace plots should look like \"fuzzy caterpillars\" (good mixing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "summary = az.summary(trace)\n",
    "print(summary)\n",
    "\n",
    "# Trace Plot\n",
    "az.plot_trace(trace)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80893a",
   "metadata": {},
   "source": [
    "## 5. Visualizing the Change Point\n",
    "Plot the posterior distribution of $\\tau$ to see where the model thinks the change occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tau samples\n",
    "tau_samples = trace.posterior['tau'].values.flatten()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.hist(tau_samples, bins=n_count, density=True, alpha=0.7, label='Posterior of $\\\\tau$')\n",
    "plt.plot(df.index, df['Price'] / df['Price'].max(), alpha=0.5, label='Scaled Price')\n",
    "plt.title('Posterior Distribution of Change Point vs Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Find the most probable change date(s)\n",
    "# Note: tau corresponds to the index\n",
    "tau_mode_idx = int(pd.DataFrame(tau_samples).mode().values[0])\n",
    "change_date = df.index[tau_mode_idx]\n",
    "print(f\"Most likely change point index: {tau_mode_idx}\")\n",
    "print(f\"Corresponding Date: {change_date.date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef720f2",
   "metadata": {},
   "source": [
    "## 6. Quantifying Impact\n",
    "Compare the posterior distributions of $\\mu_1$ (before) and $\\mu_2$ (after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07953f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_1_samples = trace.posterior['mu_1'].values.flatten()\n",
    "mu_2_samples = trace.posterior['mu_2'].values.flatten()\n",
    "\n",
    "print(f\"Mean Price Before: {mu_1_samples.mean():.2f} +/- {mu_1_samples.std():.2f}\")\n",
    "print(f\"Mean Price After: {mu_2_samples.mean():.2f} +/- {mu_2_samples.std():.2f}\")\n",
    "\n",
    "az.plot_posterior(trace, var_names=['mu_1', 'mu_2'], ref_val=0)\n",
    "plt.show()\n",
    "\n",
    "# Calculate percentage change\n",
    "pct_change_samples = (mu_2_samples - mu_1_samples) / mu_1_samples * 100\n",
    "print(f\"Average Percentage Change: {pct_change_samples.mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610b184",
   "metadata": {},
   "source": [
    "## 7. Event Association\n",
    "Correlate the detected change point with known geopolitical events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find events near the change date (e.g., within 30 days)\n",
    "window_days = 60\n",
    "mask = (events_df['Date'] >= (change_date - pd.Timedelta(days=window_days))) & \\\n",
    "       (events_df['Date'] <= (change_date + pd.Timedelta(days=window_days)))\n",
    "nearby_events = events_df[mask]\n",
    "\n",
    "print(f\"Events within {window_days} days of {change_date.date()}:\")\n",
    "if not nearby_events.empty:\n",
    "    print(nearby_events)\n",
    "else:\n",
    "    print(\"No major events found in the filtered list within this window.\")\n",
    "\n",
    "# Visual check\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df.index, df['Price'], label='Price')\n",
    "plt.axvline(x=change_date, color='red', linestyle='--', label=f'Detected Change: {change_date.date()}')\n",
    "\n",
    "# Plot event markers\n",
    "for _, row in events_df.iterrows():\n",
    "    plt.axvline(x=row['Date'], color='green', alpha=0.3, linestyle=':')\n",
    "    # Only label nearby events to avoid clutter\n",
    "    if abs((row['Date'] - change_date).days) < 1000: # Show mostly relevant ones\n",
    "         plt.text(row['Date'], df['Price'].max(), row['Event'], rotation=90, fontsize=8)\n",
    "\n",
    "plt.title('Detected Change Point and Known Events')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
